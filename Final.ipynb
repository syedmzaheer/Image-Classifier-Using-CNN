{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf586f0-78f1-4e38-a72c-aedf5b8217ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras._tf_keras.keras.datasets import cifar10\n",
    "from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras._tf_keras.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from flask import Flask, request, render_template\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6152f5b3-ef98-4d00-8ee8-61b6b2370535",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "num_classes = 10\n",
    "#epochs = 1600\n",
    "data_augmentation = True\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169f8390-0870-4955-852e-865e28ebfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# Normalize the input data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3b5b98-0d6b-4a5e-8531-a8dafcfe595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT0001\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2be8934-ae62-4641-bb6e-72e3c138e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with different hyperparameters\n",
    "learning_rates = [0.01, 0.1]\n",
    "batch_sizes = [16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6506ac65-6198-467f-b3cd-d1fdd72bc122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 16ms/step - accuracy: 0.3669 - loss: 1.7176 - val_accuracy: 0.5726 - val_loss: 1.2226\n",
      "Epoch 2/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.6062 - loss: 1.1123 - val_accuracy: 0.6547 - val_loss: 0.9939\n",
      "Epoch 3/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.6796 - loss: 0.9220 - val_accuracy: 0.6703 - val_loss: 0.9528\n",
      "Epoch 4/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 22ms/step - accuracy: 0.7207 - loss: 0.8049 - val_accuracy: 0.7004 - val_loss: 0.8655\n",
      "Epoch 5/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.7483 - loss: 0.7252 - val_accuracy: 0.7036 - val_loss: 0.8714\n",
      "Epoch 6/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.7676 - loss: 0.6630 - val_accuracy: 0.7150 - val_loss: 0.8498\n",
      "Epoch 7/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 15ms/step - accuracy: 0.7910 - loss: 0.5938 - val_accuracy: 0.7113 - val_loss: 0.8567\n",
      "Epoch 8/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 15ms/step - accuracy: 0.8047 - loss: 0.5533 - val_accuracy: 0.6999 - val_loss: 0.9124\n",
      "Epoch 9/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 20ms/step - accuracy: 0.8193 - loss: 0.5053 - val_accuracy: 0.7102 - val_loss: 0.9047\n",
      "Epoch 10/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.8376 - loss: 0.4583 - val_accuracy: 0.7097 - val_loss: 0.9092\n",
      "Epoch 11/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 21ms/step - accuracy: 0.8511 - loss: 0.4224 - val_accuracy: 0.7190 - val_loss: 0.9224\n",
      "Epoch 12/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.8610 - loss: 0.3949 - val_accuracy: 0.6806 - val_loss: 1.1093\n",
      "Epoch 13/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8713 - loss: 0.3583 - val_accuracy: 0.7045 - val_loss: 1.0450\n",
      "Epoch 14/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - accuracy: 0.8805 - loss: 0.3342 - val_accuracy: 0.7167 - val_loss: 1.0617\n",
      "Epoch 15/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8859 - loss: 0.3141 - val_accuracy: 0.7087 - val_loss: 1.1167\n",
      "Epoch 16/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.8966 - loss: 0.2848 - val_accuracy: 0.7113 - val_loss: 1.1929\n",
      "Epoch 17/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9028 - loss: 0.2683 - val_accuracy: 0.7104 - val_loss: 1.2083\n",
      "Epoch 18/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9100 - loss: 0.2494 - val_accuracy: 0.7081 - val_loss: 1.2804\n",
      "Epoch 19/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.2362 - val_accuracy: 0.7075 - val_loss: 1.3059\n",
      "Epoch 20/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.9191 - loss: 0.2263 - val_accuracy: 0.7049 - val_loss: 1.3829\n",
      "Epoch 21/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9214 - loss: 0.2199 - val_accuracy: 0.7038 - val_loss: 1.3913\n",
      "Epoch 22/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9288 - loss: 0.2053 - val_accuracy: 0.7093 - val_loss: 1.4700\n",
      "Epoch 23/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 14ms/step - accuracy: 0.9303 - loss: 0.1946 - val_accuracy: 0.7011 - val_loss: 1.5559\n",
      "Epoch 24/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 15ms/step - accuracy: 0.9340 - loss: 0.1877 - val_accuracy: 0.7056 - val_loss: 1.5306\n",
      "Epoch 25/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9363 - loss: 0.1775 - val_accuracy: 0.7058 - val_loss: 1.6108\n",
      "Epoch 26/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9373 - loss: 0.1801 - val_accuracy: 0.6967 - val_loss: 1.7168\n",
      "Epoch 27/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9395 - loss: 0.1775 - val_accuracy: 0.7024 - val_loss: 1.7174\n",
      "Epoch 28/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9403 - loss: 0.1673 - val_accuracy: 0.7011 - val_loss: 1.7377\n",
      "Epoch 29/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9445 - loss: 0.1574 - val_accuracy: 0.6991 - val_loss: 1.9290\n",
      "Epoch 30/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - accuracy: 0.9436 - loss: 0.1592 - val_accuracy: 0.7048 - val_loss: 1.7998\n",
      "Epoch 31/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9472 - loss: 0.1514 - val_accuracy: 0.6976 - val_loss: 1.9649\n",
      "Epoch 32/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9483 - loss: 0.1497 - val_accuracy: 0.6997 - val_loss: 1.9442\n",
      "Epoch 33/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9494 - loss: 0.1426 - val_accuracy: 0.7009 - val_loss: 1.9844\n",
      "Epoch 34/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9476 - loss: 0.1511 - val_accuracy: 0.7040 - val_loss: 1.9249\n",
      "Epoch 35/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9510 - loss: 0.1416 - val_accuracy: 0.6999 - val_loss: 2.0470\n",
      "Epoch 36/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 0.1352 - val_accuracy: 0.7008 - val_loss: 2.0552\n",
      "Epoch 37/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9545 - loss: 0.1279 - val_accuracy: 0.6919 - val_loss: 2.1096\n",
      "Epoch 38/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12ms/step - accuracy: 0.9565 - loss: 0.1251 - val_accuracy: 0.7047 - val_loss: 2.0677\n",
      "Epoch 39/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9560 - loss: 0.1325 - val_accuracy: 0.7023 - val_loss: 2.1214\n",
      "Epoch 40/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12ms/step - accuracy: 0.9531 - loss: 0.1424 - val_accuracy: 0.6954 - val_loss: 2.1315\n",
      "Epoch 41/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9559 - loss: 0.1293 - val_accuracy: 0.7006 - val_loss: 2.2339\n",
      "Epoch 42/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9536 - loss: 0.1387 - val_accuracy: 0.6965 - val_loss: 2.2285\n",
      "Epoch 43/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.9603 - loss: 0.1162 - val_accuracy: 0.6967 - val_loss: 2.2200\n",
      "Epoch 44/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9582 - loss: 0.1255 - val_accuracy: 0.6941 - val_loss: 2.3695\n",
      "Epoch 45/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9570 - loss: 0.1313 - val_accuracy: 0.6940 - val_loss: 2.3753\n",
      "Epoch 46/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9577 - loss: 0.1248 - val_accuracy: 0.6962 - val_loss: 2.3389\n",
      "Epoch 47/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.1214 - val_accuracy: 0.6924 - val_loss: 2.4589\n",
      "Epoch 48/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9569 - loss: 0.1334 - val_accuracy: 0.7005 - val_loss: 2.3740\n",
      "Epoch 49/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.1155 - val_accuracy: 0.6954 - val_loss: 2.5098\n",
      "Epoch 50/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1207 - val_accuracy: 0.6944 - val_loss: 2.5626\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.9727 - loss: 0.0828 - val_accuracy: 0.7091 - val_loss: 2.5401\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0567 - val_accuracy: 0.7070 - val_loss: 2.7354\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9801 - loss: 0.0594 - val_accuracy: 0.6920 - val_loss: 2.8019\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.0495 - val_accuracy: 0.7040 - val_loss: 2.9724\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9768 - loss: 0.0727 - val_accuracy: 0.7032 - val_loss: 2.9881\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9809 - loss: 0.0576 - val_accuracy: 0.7014 - val_loss: 3.1919\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9846 - loss: 0.0464 - val_accuracy: 0.7063 - val_loss: 3.0377\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.0541 - val_accuracy: 0.6974 - val_loss: 3.2057\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9793 - loss: 0.0627 - val_accuracy: 0.7025 - val_loss: 3.1804\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9853 - loss: 0.0463 - val_accuracy: 0.6963 - val_loss: 3.2858\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9814 - loss: 0.0583 - val_accuracy: 0.6978 - val_loss: 3.1595\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9796 - loss: 0.0651 - val_accuracy: 0.7089 - val_loss: 3.2030\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0555 - val_accuracy: 0.7087 - val_loss: 3.4420\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9790 - loss: 0.0651 - val_accuracy: 0.6992 - val_loss: 3.3629\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9814 - loss: 0.0615 - val_accuracy: 0.6975 - val_loss: 3.4322\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9815 - loss: 0.0621 - val_accuracy: 0.7053 - val_loss: 3.3471\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9826 - loss: 0.0605 - val_accuracy: 0.6997 - val_loss: 3.4608\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9833 - loss: 0.0518 - val_accuracy: 0.7008 - val_loss: 3.5833\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9801 - loss: 0.0640 - val_accuracy: 0.7017 - val_loss: 3.4319\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9849 - loss: 0.0488 - val_accuracy: 0.7008 - val_loss: 3.4095\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0576 - val_accuracy: 0.6997 - val_loss: 3.5584\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9853 - loss: 0.0507 - val_accuracy: 0.6993 - val_loss: 3.5769\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 0.0603 - val_accuracy: 0.6974 - val_loss: 3.7685\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9825 - loss: 0.0568 - val_accuracy: 0.6999 - val_loss: 3.5923\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9828 - loss: 0.0525 - val_accuracy: 0.7069 - val_loss: 3.7918\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9807 - loss: 0.0639 - val_accuracy: 0.7030 - val_loss: 3.6828\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9833 - loss: 0.0541 - val_accuracy: 0.6995 - val_loss: 3.7276\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9864 - loss: 0.0471 - val_accuracy: 0.6995 - val_loss: 3.6980\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9848 - loss: 0.0510 - val_accuracy: 0.7072 - val_loss: 3.9166\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9813 - loss: 0.0649 - val_accuracy: 0.6961 - val_loss: 3.7651\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9829 - loss: 0.0556 - val_accuracy: 0.7024 - val_loss: 3.8752\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9848 - loss: 0.0518 - val_accuracy: 0.7062 - val_loss: 3.8184\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9830 - loss: 0.0592 - val_accuracy: 0.6964 - val_loss: 4.0810\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.0591 - val_accuracy: 0.6961 - val_loss: 3.9472\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9849 - loss: 0.0513 - val_accuracy: 0.6928 - val_loss: 3.8644\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0573 - val_accuracy: 0.6989 - val_loss: 3.9555\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9830 - loss: 0.0587 - val_accuracy: 0.6930 - val_loss: 3.9394\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9862 - loss: 0.0444 - val_accuracy: 0.7034 - val_loss: 3.9973\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9825 - loss: 0.0625 - val_accuracy: 0.6971 - val_loss: 3.9850\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.0471 - val_accuracy: 0.6960 - val_loss: 4.2959\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9780 - loss: 0.0802 - val_accuracy: 0.7045 - val_loss: 3.9828\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9847 - loss: 0.0540 - val_accuracy: 0.7014 - val_loss: 4.1777\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9825 - loss: 0.0658 - val_accuracy: 0.6927 - val_loss: 4.0826\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9865 - loss: 0.0468 - val_accuracy: 0.7015 - val_loss: 4.1305\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9840 - loss: 0.0571 - val_accuracy: 0.6952 - val_loss: 4.1776\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0653 - val_accuracy: 0.6939 - val_loss: 4.1533\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9841 - loss: 0.0565 - val_accuracy: 0.6921 - val_loss: 4.2846\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9790 - loss: 0.0757 - val_accuracy: 0.7006 - val_loss: 4.1879\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9862 - loss: 0.0470 - val_accuracy: 0.6973 - val_loss: 4.3213\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9818 - loss: 0.0633 - val_accuracy: 0.7036 - val_loss: 4.1850\n",
      "Epoch 1/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.1113 - val_accuracy: 0.6854 - val_loss: 4.1320\n",
      "Epoch 2/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.1236 - val_accuracy: 0.6899 - val_loss: 4.2591\n",
      "Epoch 3/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.1203 - val_accuracy: 0.6954 - val_loss: 3.8351\n",
      "Epoch 4/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.9704 - loss: 0.1209 - val_accuracy: 0.6883 - val_loss: 3.7846\n",
      "Epoch 5/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9662 - loss: 0.1285 - val_accuracy: 0.6951 - val_loss: 3.8451\n",
      "Epoch 6/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.1179 - val_accuracy: 0.6917 - val_loss: 4.0108\n",
      "Epoch 7/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9674 - loss: 0.1267 - val_accuracy: 0.6946 - val_loss: 3.7506\n",
      "Epoch 8/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9731 - loss: 0.0982 - val_accuracy: 0.6962 - val_loss: 3.9616\n",
      "Epoch 9/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.1193 - val_accuracy: 0.6974 - val_loss: 3.6279\n",
      "Epoch 10/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.1085 - val_accuracy: 0.6916 - val_loss: 3.6464\n",
      "Epoch 11/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9712 - loss: 0.1019 - val_accuracy: 0.6808 - val_loss: 3.7479\n",
      "Epoch 12/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.1196 - val_accuracy: 0.6896 - val_loss: 3.6983\n",
      "Epoch 13/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.1099 - val_accuracy: 0.6987 - val_loss: 3.6888\n",
      "Epoch 14/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.1166 - val_accuracy: 0.6877 - val_loss: 3.7850\n",
      "Epoch 15/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.1138 - val_accuracy: 0.6887 - val_loss: 3.7019\n",
      "Epoch 16/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9747 - loss: 0.0893 - val_accuracy: 0.6892 - val_loss: 3.8680\n",
      "Epoch 17/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9709 - loss: 0.1080 - val_accuracy: 0.6878 - val_loss: 3.8453\n",
      "Epoch 18/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9696 - loss: 0.1171 - val_accuracy: 0.6880 - val_loss: 4.0209\n",
      "Epoch 19/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.1188 - val_accuracy: 0.6915 - val_loss: 3.9729\n",
      "Epoch 20/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0962 - val_accuracy: 0.6912 - val_loss: 4.0445\n",
      "Epoch 21/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.1109 - val_accuracy: 0.6926 - val_loss: 4.0149\n",
      "Epoch 22/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.1000 - val_accuracy: 0.6928 - val_loss: 4.0566\n",
      "Epoch 23/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9690 - loss: 0.1186 - val_accuracy: 0.6963 - val_loss: 3.9069\n",
      "Epoch 24/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.1208 - val_accuracy: 0.6882 - val_loss: 4.1702\n",
      "Epoch 25/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.0959 - val_accuracy: 0.6923 - val_loss: 4.0713\n",
      "Epoch 26/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.1191 - val_accuracy: 0.6835 - val_loss: 4.2505\n",
      "Epoch 27/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9725 - loss: 0.1049 - val_accuracy: 0.6897 - val_loss: 4.2353\n",
      "Epoch 28/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9702 - loss: 0.1186 - val_accuracy: 0.6858 - val_loss: 4.2323\n",
      "Epoch 29/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9719 - loss: 0.1036 - val_accuracy: 0.6894 - val_loss: 4.2510\n",
      "Epoch 30/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.1062 - val_accuracy: 0.6892 - val_loss: 4.1696\n",
      "Epoch 31/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9715 - loss: 0.1094 - val_accuracy: 0.6957 - val_loss: 4.1298\n",
      "Epoch 32/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 0.1082 - val_accuracy: 0.6861 - val_loss: 4.2852\n",
      "Epoch 33/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9719 - loss: 0.1135 - val_accuracy: 0.6953 - val_loss: 4.1420\n",
      "Epoch 34/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.0993 - val_accuracy: 0.6858 - val_loss: 4.2911\n",
      "Epoch 35/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.1275 - val_accuracy: 0.6849 - val_loss: 4.2906\n",
      "Epoch 36/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.1013 - val_accuracy: 0.6957 - val_loss: 4.3282\n",
      "Epoch 37/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9731 - loss: 0.0997 - val_accuracy: 0.6852 - val_loss: 4.4522\n",
      "Epoch 38/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - accuracy: 0.9734 - loss: 0.1072 - val_accuracy: 0.6977 - val_loss: 4.4359\n",
      "Epoch 39/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9738 - loss: 0.1070 - val_accuracy: 0.6938 - val_loss: 4.2246\n",
      "Epoch 40/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.0929 - val_accuracy: 0.6936 - val_loss: 4.4496\n",
      "Epoch 41/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9730 - loss: 0.1067 - val_accuracy: 0.6845 - val_loss: 4.3874\n",
      "Epoch 42/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.1027 - val_accuracy: 0.6934 - val_loss: 4.4271\n",
      "Epoch 43/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.1017 - val_accuracy: 0.6979 - val_loss: 4.3663\n",
      "Epoch 44/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.1077 - val_accuracy: 0.6975 - val_loss: 4.2740\n",
      "Epoch 45/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9736 - loss: 0.1041 - val_accuracy: 0.6915 - val_loss: 4.8306\n",
      "Epoch 46/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.1202 - val_accuracy: 0.6951 - val_loss: 4.4371\n",
      "Epoch 47/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0961 - val_accuracy: 0.6829 - val_loss: 4.6181\n",
      "Epoch 48/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9717 - loss: 0.1213 - val_accuracy: 0.6995 - val_loss: 4.6731\n",
      "Epoch 49/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.1136 - val_accuracy: 0.6868 - val_loss: 4.5221\n",
      "Epoch 50/50\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.9726 - loss: 0.1119 - val_accuracy: 0.6905 - val_loss: 4.4898\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9819 - loss: 0.0676 - val_accuracy: 0.6931 - val_loss: 4.8921\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9867 - loss: 0.0504 - val_accuracy: 0.6966 - val_loss: 4.7307\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.0460 - val_accuracy: 0.6989 - val_loss: 4.9352\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9880 - loss: 0.0471 - val_accuracy: 0.7025 - val_loss: 5.1040\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9879 - loss: 0.0483 - val_accuracy: 0.6902 - val_loss: 5.2916\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9874 - loss: 0.0488 - val_accuracy: 0.7006 - val_loss: 5.0438\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.0510 - val_accuracy: 0.6928 - val_loss: 5.2590\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.0537 - val_accuracy: 0.6992 - val_loss: 5.3873\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9862 - loss: 0.0542 - val_accuracy: 0.7026 - val_loss: 5.6306\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9871 - loss: 0.0512 - val_accuracy: 0.7001 - val_loss: 5.5266\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9860 - loss: 0.0594 - val_accuracy: 0.6943 - val_loss: 5.5377\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.9886 - loss: 0.0491 - val_accuracy: 0.7005 - val_loss: 5.7546\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9839 - loss: 0.0743 - val_accuracy: 0.6988 - val_loss: 5.4505\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9882 - loss: 0.0480 - val_accuracy: 0.6985 - val_loss: 5.7932\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9864 - loss: 0.0608 - val_accuracy: 0.6959 - val_loss: 5.6950\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9887 - loss: 0.0438 - val_accuracy: 0.6914 - val_loss: 5.9471\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9867 - loss: 0.0560 - val_accuracy: 0.6959 - val_loss: 5.9196\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9882 - loss: 0.0520 - val_accuracy: 0.6932 - val_loss: 6.2161\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9871 - loss: 0.0550 - val_accuracy: 0.6921 - val_loss: 6.1121\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9888 - loss: 0.0540 - val_accuracy: 0.6891 - val_loss: 5.9064\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9879 - loss: 0.0513 - val_accuracy: 0.6890 - val_loss: 6.1376\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9841 - loss: 0.0788 - val_accuracy: 0.6987 - val_loss: 5.8745\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9880 - loss: 0.0488 - val_accuracy: 0.6989 - val_loss: 6.0055\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9887 - loss: 0.0451 - val_accuracy: 0.6913 - val_loss: 6.1740\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9874 - loss: 0.0590 - val_accuracy: 0.6904 - val_loss: 6.1540\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9883 - loss: 0.0548 - val_accuracy: 0.6964 - val_loss: 6.0828\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9858 - loss: 0.0713 - val_accuracy: 0.6994 - val_loss: 6.2289\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.6928 - val_loss: 6.3399\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9873 - loss: 0.0548 - val_accuracy: 0.6935 - val_loss: 6.5101\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.9872 - loss: 0.0570 - val_accuracy: 0.7005 - val_loss: 6.3871\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9872 - loss: 0.0640 - val_accuracy: 0.7007 - val_loss: 6.3419\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9891 - loss: 0.0443 - val_accuracy: 0.6932 - val_loss: 6.3781\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9884 - loss: 0.0501 - val_accuracy: 0.6932 - val_loss: 6.4088\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9845 - loss: 0.0746 - val_accuracy: 0.6980 - val_loss: 6.2400\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9868 - loss: 0.0596 - val_accuracy: 0.6971 - val_loss: 6.8486\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9856 - loss: 0.0733 - val_accuracy: 0.6894 - val_loss: 6.6764\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9876 - loss: 0.0604 - val_accuracy: 0.6867 - val_loss: 6.6811\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9858 - loss: 0.0725 - val_accuracy: 0.6997 - val_loss: 6.6215\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 25ms/step - accuracy: 0.9870 - loss: 0.0608 - val_accuracy: 0.6906 - val_loss: 6.7539\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.9889 - loss: 0.0477 - val_accuracy: 0.6940 - val_loss: 6.8705\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9871 - loss: 0.0589 - val_accuracy: 0.6990 - val_loss: 6.9770\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.9882 - loss: 0.0568 - val_accuracy: 0.6952 - val_loss: 6.7159\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9893 - loss: 0.0537 - val_accuracy: 0.6975 - val_loss: 6.8081\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9873 - loss: 0.0594 - val_accuracy: 0.6961 - val_loss: 6.9305\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9850 - loss: 0.0731 - val_accuracy: 0.6897 - val_loss: 7.0072\n"
     ]
    }
   ],
   "source": [
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=\"Adam\",\n",
    "            metrics=['accuracy'])\n",
    "        m1=model.fit(x_train, y_train,\n",
    "            batch_size=bs,\n",
    "            epochs=50,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d82d7b0-28df-4e07-8de9-9938a3fae876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6974 - loss: 6.8195\n",
      "Learning Rate: 0.1, Batch Size: 32, Optimizer: <class 'keras.src.optimizers.adam.Adam'>, Accuracy: 0.690\n"
     ]
    }
   ],
   "source": [
    " # Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Learning Rate: {lr}, Batch Size: {bs}, Optimizer: {Adam}, Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91b686a-d547-4b66-a716-e0a59d544b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model using data augmentation and regularization\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fffcccca-4730-40d3-be7d-4b5b5363f3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m   1/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:37\u001b[0m 4s/step - accuracy: 0.1562 - loss: 1.4733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT0001\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 42ms/step - accuracy: 0.1441 - loss: 1.6514 - val_accuracy: 0.1623 - val_loss: 11.6326\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.1152 - loss: 1.7997 - val_accuracy: 0.1135 - val_loss: 21.8212\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.1066 - loss: 1.8139 - val_accuracy: 0.1004 - val_loss: 43.3032\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 46ms/step - accuracy: 0.0991 - loss: 1.8214 - val_accuracy: 0.1009 - val_loss: 42.5993\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.1012 - loss: 1.8249 - val_accuracy: 0.1009 - val_loss: 42.5808\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 44ms/step - accuracy: 0.0973 - loss: 1.8334 - val_accuracy: 0.1005 - val_loss: 43.4047\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.1012 - loss: 1.8225 - val_accuracy: 0.1002 - val_loss: 79.1674\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.1001 - loss: 1.8247 - val_accuracy: 0.1002 - val_loss: 79.6425\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.0986 - loss: 1.8313 - val_accuracy: 0.1002 - val_loss: 78.2423\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.0980 - loss: 1.8218 - val_accuracy: 0.1002 - val_loss: 78.2445\n"
     ]
    }
   ],
   "source": [
    "model.add(Dropout(0.2))\n",
    "model.compile(optimizer= 'adam' , loss= keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "m1 = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856ea58-bb8f-43c3-8f79-d344a4bbcd09",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
